{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc38e73",
   "metadata": {},
   "source": [
    "# Creating The Artificial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f5985f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name Age    Address Qualification Score        Date\n",
      "0         Jai  44     Nagpur           MCA    31  2022-05-11\n",
      "1        None  51        NaN         B.com    72  2020-10-21\n",
      "2      Princi  48    Lucknow           Msc    88  2022-12-27\n",
      "3      Gaurav  58    Lucknow           Msc    77  2021-06-05\n",
      "4      Mukesh  26  Allahabad       Diploma    81  2021-09-05\n",
      "...       ...  ..        ...           ...   ...         ...\n",
      "2495  Praveen  35    Kannauj           B.A    90  2023-01-16\n",
      "2496   Suresh  29  Allahabad          None    58  2022-10-25\n",
      "2497     None  45     Nagpur           Msc    22  2021-01-26\n",
      "2498   Mukesh  56       None       Diploma    32  2022-01-25\n",
      "2499    Vijay  38    Jaunpur           Msc    84  2022-08-02\n",
      "\n",
      "[2500 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Add The Columns\n",
    "names = ['Jai', 'Anuj', 'Princi', 'Gaurav', 'Abhi', 'Ravi', 'Amit',\n",
    "         'Rahul', 'Kamal', 'Vikram', 'Sachin', 'Ankit', 'Mukesh', 'Saurabh', \n",
    "         'Rajesh', 'Suresh', 'Praveen', 'Vijay', 'Sandeep', 'Sunil', 'Deepak',\n",
    "         'Vinod', 'Manish', 'Tarun',None,None]\n",
    "addresses = ['Nagpur', 'Kanpur', 'Allahabad', 'Kannauj', 'Jaunpur', 'Aligarh',\n",
    "             'Lucknow', 'Bhopal',None,None]\n",
    "qualifications = ['Msc', 'MA', 'MCA', 'Phd', 'B.Tech', 'B.com', 'B.A',\n",
    "                  'Diploma',None,None]\n",
    "data1 = {'Name': [], 'Age': [], 'Address': [], 'Qualification': [], 'Score': []}\n",
    "\n",
    "for i in range(2000):\n",
    "    data1['Name'].append(random.choice(names))\n",
    "    data1['Age'].append(random.randint(22, 60))\n",
    "    data1['Address'].append(random.choice(addresses))\n",
    "    data1['Qualification'].append(random.choice(qualifications))\n",
    "    data1['Score'].append(random.randint(20, 100))\n",
    "\n",
    "    \n",
    "       \n",
    "df = pd.DataFrame(data1)\n",
    "   \n",
    "# Adding A Date column\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2023, 2, 4)\n",
    "time_between_dates = end_date - start_date\n",
    "days_between_dates = time_between_dates.days\n",
    "df['Date'] = [start_date + timedelta(days=random.randint(0, days_between_dates)) for i in range(df.shape[0])]\n",
    "\n",
    "# Changing the Data Type\n",
    "df['Date'] = df['Date'].astype(str)\n",
    "df['Age'] = df['Age'].astype(str)\n",
    "df['Score'] = df['Score'].astype(str)\n",
    "\n",
    "# Add The Duplicated Data\n",
    "duplicated_rows = df.loc[random.sample(list(range(2000)), 500)].copy()\n",
    "df = df.append(duplicated_rows, ignore_index=True)\n",
    "rows = list(range(df.shape[0]))\n",
    "\n",
    "\n",
    "# Add The Null Data\n",
    "rows = random.sample(rows, int(df.shape[0] * 0.05))\n",
    "\n",
    "columns = random.sample(list(df.columns), int(df.shape[1] * 0.2))\n",
    "\n",
    "for column in columns:\n",
    "    df.loc[rows, column] = np.nan\n",
    "    \n",
    "    \n",
    "    \n",
    "# Shuffle The Data\n",
    "df = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Final Data\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e237c",
   "metadata": {},
   "source": [
    "We have generated this dataset containing duplicate and missing values for the purpose of demonstrating the significance of data cleaning and improving our understanding of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93124b77",
   "metadata": {},
   "source": [
    "# Data Exploration and Data Cleaning\n",
    "\n",
    "Data Exploration is the process of analyzing and summarizing the characteristics and patterns of a dataset in order to gain a better understanding of the data and identify any potential issues that may need to be addressed before using the data for further analysis or modeling\n",
    "\n",
    "Data Cleaning is the process of correcting or removing errors, inconsistencies, and inaccuracies in a dataset in order to improve the quality and reliability of the data for analysis and modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5d9430",
   "metadata": {},
   "source": [
    "### Checking Anomalies in Data Statistics and Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b905fc4d",
   "metadata": {},
   "source": [
    "The **describe method** can be useful for quickly getting an overview of the distribution of your data and detecting any outliers or anomalies. It can also help identify any missing or non-numeric values in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5a51873f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Address</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Score</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2315</td>\n",
       "      <td>2500</td>\n",
       "      <td>1900</td>\n",
       "      <td>2053</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Suresh</td>\n",
       "      <td>54</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>B.com</td>\n",
       "      <td>74</td>\n",
       "      <td>2020-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>113</td>\n",
       "      <td>87</td>\n",
       "      <td>274</td>\n",
       "      <td>280</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name   Age Address Qualification Score        Date\n",
       "count     2315  2500    1900          2053  2500        2500\n",
       "unique      24    39       8             8    81         933\n",
       "top     Suresh    54  Nagpur         B.com    74  2020-03-09\n",
       "freq       113    87     274           280    46          11"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e60b1a",
   "metadata": {},
   "source": [
    "The info method in pandas is used to obtain a concise summary of a dataframe, including the number of non-missing values in each column, the data type of each column, and the memory usage of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d530b63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Name           2315 non-null   object\n",
      " 1   Age            2500 non-null   object\n",
      " 2   Address        1900 non-null   object\n",
      " 3   Qualification  2053 non-null   object\n",
      " 4   Score          2500 non-null   object\n",
      " 5   Date           2500 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fb5af6",
   "metadata": {},
   "source": [
    "It appears that integer and datetime data are stored as string data types. To ensure proper data analysis and manipulation, it is necessary to perform data type conversion and convert these values into their appropriate integer and datetime data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e0d9e",
   "metadata": {},
   "source": [
    "### Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2d1de203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Score'] = df['Score'].astype(int)\n",
    "df['Age'] = df['Age'].astype(float)\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5a66d6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Name           2315 non-null   object        \n",
      " 1   Age            2500 non-null   float64       \n",
      " 2   Address        1900 non-null   object        \n",
      " 3   Qualification  2053 non-null   object        \n",
      " 4   Score          2500 non-null   int32         \n",
      " 5   Date           2500 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), int32(1), object(3)\n",
      "memory usage: 107.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903080f9",
   "metadata": {},
   "source": [
    "### Checking For Duplicated Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e4d284",
   "metadata": {},
   "source": [
    "The duplicated method in pandas is used to check for duplicate rows in a dataframe. The method returns a boolean series with True values for the rows that are duplicates and False values for the unique rows.\n",
    "\n",
    "The value_counts method can then be applied to the resulting series to get a count of the unique values, i.e., the number of duplicate and unique rows in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f0011daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2032\n",
       "True      468\n",
       "dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d6b042",
   "metadata": {},
   "source": [
    "Keep or drop duplicates depends on the purpose, sometimes keep for accuracy and sometimes drop to avoid mistakes, based on the goal of the analysis.\n",
    "In this Case We are dropping the Duplicated Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d08f0cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2032\n",
       "dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e716ba0",
   "metadata": {},
   "source": [
    "### Checking for Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ceddde",
   "metadata": {},
   "source": [
    "The **isnull** method in pandas is used to check for missing values in a dataframe. The method returns a dataframe of the same shape as the original dataframe, with True values in the cells where the corresponding value in the original dataframe is missing (i.e., NaN or None), and False values in the cells where the corresponding value is not missing.\n",
    "\n",
    "The **sum** method can then be applied to the resulting dataframe to calculate the number of missing values in each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc78fe09",
   "metadata": {},
   "source": [
    "Adding Null Values In the Data For Null Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "62cc1864",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.random.choice(df.index, size=250, replace=False)\n",
    "df.loc[rows, 'Age'] = np.nan\n",
    "df.loc[rows, 'Score'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "abde3fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name             148\n",
       "Age              250\n",
       "Address          501\n",
       "Qualification    365\n",
       "Score            250\n",
       "Date               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99491abb",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b77c4ee",
   "metadata": {},
   "source": [
    "1.For The Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4021ad1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name               0\n",
       "Age              250\n",
       "Address            0\n",
       "Qualification      0\n",
       "Score            250\n",
       "Date               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name'].fillna('Unknown',inplace=True)\n",
    "df['Address'].fillna('Unknown',inplace=True)\n",
    "df['Qualification'].fillna('Unknown',inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c33842d",
   "metadata": {},
   "source": [
    "2.For The Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f3257",
   "metadata": {},
   "source": [
    "(a) Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2319550a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown    44\n",
       "Msc        32\n",
       "B.com      31\n",
       "MA         28\n",
       "Phd        28\n",
       "B.Tech     25\n",
       "B.A        23\n",
       "Diploma    20\n",
       "MCA        19\n",
       "Name: Qualification, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Age'].isnull() ==True,'Qualification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c43d281e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown    21\n",
       "Praveen    17\n",
       "Amit       14\n",
       "Vinod      12\n",
       "Saurabh    12\n",
       "Vikram     11\n",
       "Kamal      11\n",
       "Manish     11\n",
       "Rahul      11\n",
       "Sandeep    11\n",
       "Sunil      10\n",
       "Suresh     10\n",
       "Gaurav      9\n",
       "Abhi        9\n",
       "Anuj        9\n",
       "Sachin      9\n",
       "Jai         9\n",
       "Mukesh      8\n",
       "Vijay       8\n",
       "Ravi        7\n",
       "Tarun       7\n",
       "Ankit       7\n",
       "Rajesh      6\n",
       "Deepak      6\n",
       "Princi      5\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Age'].isnull() ==True,'Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6ce5bb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown      65\n",
       "Kannauj      30\n",
       "Kanpur       30\n",
       "Lucknow      25\n",
       "Bhopal       25\n",
       "Aligarh      21\n",
       "Jaunpur      18\n",
       "Nagpur       18\n",
       "Allahabad    18\n",
       "Name: Address, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Age'].isnull() ==True,'Address'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f793eea5",
   "metadata": {},
   "source": [
    "Creating Separate Date Column to Check for Variation in Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8a1ce4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_year'] = df.Date.dt.year\n",
    "df['start_month'] = df.Date.dt.month_name()\n",
    "df['start_date'] = df.Date.dt.day\n",
    "df['week_day']  = df.Date.dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b22c765d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021    85\n",
       "2020    80\n",
       "2022    80\n",
       "2023     5\n",
       "Name: start_year, dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Age'].isnull() ==True,'start_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a09d4257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "April        27\n",
       "August       26\n",
       "June         25\n",
       "May          24\n",
       "July         24\n",
       "January      23\n",
       "February     20\n",
       "December     20\n",
       "March        18\n",
       "November     16\n",
       "October      14\n",
       "September    13\n",
       "Name: start_month, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Age'].isnull() ==True,'start_month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e9788993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21    13\n",
       "22    13\n",
       "23    12\n",
       "26    12\n",
       "14    11\n",
       "5     10\n",
       "28    10\n",
       "11     9\n",
       "19     9\n",
       "12     9\n",
       "9      9\n",
       "1      9\n",
       "10     9\n",
       "25     8\n",
       "17     8\n",
       "15     8\n",
       "29     8\n",
       "20     8\n",
       "16     8\n",
       "4      8\n",
       "18     7\n",
       "8      6\n",
       "6      6\n",
       "24     6\n",
       "31     5\n",
       "2      5\n",
       "27     5\n",
       "7      5\n",
       "3      5\n",
       "13     5\n",
       "30     4\n",
       "Name: start_date, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Age'].isnull() ==True,'start_date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9ec16545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sunday       46\n",
       "Wednesday    40\n",
       "Monday       38\n",
       "Tuesday      38\n",
       "Friday       30\n",
       "Thursday     29\n",
       "Saturday     29\n",
       "Name: week_day, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Age'].isnull() ==True,'week_day'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02e5fc",
   "metadata": {},
   "source": [
    "Since the missing values don't seem to be connected to any of the other columns, we can fill them by by taking the mean of the two closest non-null values in the same column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2fc7536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def fill_na_mean_closest_two(col):\n",
    "    \"\"\"\n",
    "    Fills missing values in the column by taking the mean of the two closest non-null values.\n",
    "    \"\"\"\n",
    "    not_null = col.notnull()\n",
    "    idx = col.index[not_null]\n",
    "    val = col.loc[not_null].values\n",
    "    \n",
    "    filled = col.copy()\n",
    "    for i, row in col[~not_null].iteritems():\n",
    "        j = np.searchsorted(idx, i, side='left')\n",
    "        if j > 0 and (j == len(idx) or math.fabs(i - idx[j-1]) < math.fabs(i - idx[j])):\n",
    "            j -= 1\n",
    "        filled.loc[i] = (val[j-1] + val[j]) / 2\n",
    "    return filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "35960fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = fill_na_mean_closest_two(df['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e675999c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name               0\n",
       "Age                0\n",
       "Address            0\n",
       "Qualification      0\n",
       "Score            250\n",
       "Date               0\n",
       "start_year         0\n",
       "start_month        0\n",
       "start_date         0\n",
       "week_day           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b9e36852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name               0\n",
       "Age                0\n",
       "Address            0\n",
       "Qualification      0\n",
       "Score            250\n",
       "Date               0\n",
       "start_year         0\n",
       "start_month        0\n",
       "start_date         0\n",
       "week_day           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1763ec0",
   "metadata": {},
   "source": [
    "(b) Score\n",
    "\n",
    "Lets Repeat the Same method for the Score Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "26a22953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown    44\n",
       "Msc        32\n",
       "B.com      31\n",
       "MA         28\n",
       "Phd        28\n",
       "B.Tech     25\n",
       "B.A        23\n",
       "Diploma    20\n",
       "MCA        19\n",
       "Name: Qualification, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Score'].isnull() ==True,'Qualification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c60a2599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown    47\n",
       "Gaurav     25\n",
       "Deepak     20\n",
       "Manish     19\n",
       "Ankit      19\n",
       "Princi     19\n",
       "Anuj       18\n",
       "Ravi       18\n",
       "Sunil      18\n",
       "Suresh     17\n",
       "Praveen    17\n",
       "Jai        17\n",
       "Rahul      17\n",
       "Sachin     16\n",
       "Vijay      16\n",
       "Saurabh    16\n",
       "Vikram     14\n",
       "Rajesh     14\n",
       "Vinod      13\n",
       "Tarun      12\n",
       "Mukesh     12\n",
       "Abhi       12\n",
       "Kamal      10\n",
       "Sandeep     9\n",
       "Amit        9\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Score'].isnull() ==True,'Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "caca17c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown      85\n",
       "Aligarh      50\n",
       "Nagpur       46\n",
       "Allahabad    45\n",
       "Lucknow      43\n",
       "Bhopal       42\n",
       "Kanpur       38\n",
       "Kannauj      38\n",
       "Jaunpur      37\n",
       "Name: Address, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Score'].isnull() ==True,'Address'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cf4e1e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    92\n",
       "2022    82\n",
       "2021    74\n",
       "2023     2\n",
       "Name: start_year, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Score'].isnull() ==True,'start_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "83450cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "March        29\n",
       "January      26\n",
       "August       24\n",
       "April        22\n",
       "May          20\n",
       "February     20\n",
       "November     20\n",
       "October      20\n",
       "July         19\n",
       "June         19\n",
       "September    17\n",
       "December     14\n",
       "Name: start_month, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Score'].isnull() ==True,'start_month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "154a62f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    15\n",
       "17    14\n",
       "22    13\n",
       "30    12\n",
       "8     11\n",
       "20    11\n",
       "26    11\n",
       "9     10\n",
       "13    10\n",
       "6     10\n",
       "3     10\n",
       "5     10\n",
       "27     9\n",
       "11     9\n",
       "12     9\n",
       "18     8\n",
       "23     8\n",
       "24     8\n",
       "15     7\n",
       "10     7\n",
       "7      7\n",
       "25     7\n",
       "14     7\n",
       "21     7\n",
       "2      4\n",
       "29     4\n",
       "4      3\n",
       "28     3\n",
       "16     3\n",
       "1      3\n",
       "Name: start_date, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Score'].isnull() ==True,'start_date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9d14382b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sunday       48\n",
       "Thursday     35\n",
       "Friday       35\n",
       "Saturday     35\n",
       "Wednesday    34\n",
       "Monday       33\n",
       "Tuesday      30\n",
       "Name: week_day, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Score'].isnull() ==True,'week_day'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d255207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Score'] = fill_na_mean_closest_two(df['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "321029f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name             0\n",
       "Age              0\n",
       "Address          0\n",
       "Qualification    0\n",
       "Score            0\n",
       "Date             0\n",
       "start_year       0\n",
       "start_month      0\n",
       "start_date       0\n",
       "week_day         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1104717",
   "metadata": {},
   "source": [
    "# Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948659a6",
   "metadata": {},
   "source": [
    "This Method performs outlier detection on a specific column in a pandas dataframe. The method used to detect outliers is based on the Z-score, which is a standardized measure of how many standard deviations a value is from the mean.\n",
    "\n",
    "\n",
    "Outlier detection is an important step in data cleaning and preparation. Outliers can significantly affect the results of statistical analysis, so it's important to identify and handle them appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fe194a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Name, Age, Address, Qualification, Score, Date, start_year, start_month, start_date, week_day]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "mean = df['Score'].mean()\n",
    "std = df['Score'].std()\n",
    "\n",
    "z_scores = (df['Score'] - mean) / std\n",
    "outliers = df[np.abs(z_scores) > 3]\n",
    "\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "156287fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Name, Age, Address, Qualification, Score, Date, start_year, start_month, start_date, week_day]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "mean = df['Age'].mean()\n",
    "std = df['Age'].std()\n",
    "\n",
    "z_scores = (df['Age'] - mean) / std\n",
    "outliers = df[np.abs(z_scores) > 3]\n",
    "\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f63a8ac",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "After thoroughly reviewing the data, we discovered that there were duplicates, missing values, and incorrect data types present. In order to enhance the quality and reliability of the data, we conducted both Data Exploration and Data Cleaning. The outcome of these processes has resulted in a cleaned dataset, which can now be used for further analysis or modeling. Here is the cleaned data ready for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "17474988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Address</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Score</th>\n",
       "      <th>Date</th>\n",
       "      <th>start_year</th>\n",
       "      <th>start_month</th>\n",
       "      <th>start_date</th>\n",
       "      <th>week_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jai</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>MCA</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>2022</td>\n",
       "      <td>May</td>\n",
       "      <td>11</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>B.com</td>\n",
       "      <td>59.5</td>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>2020</td>\n",
       "      <td>October</td>\n",
       "      <td>21</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Princi</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Lucknow</td>\n",
       "      <td>Msc</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>2022</td>\n",
       "      <td>December</td>\n",
       "      <td>27</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gaurav</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Lucknow</td>\n",
       "      <td>Msc</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2021-06-05</td>\n",
       "      <td>2021</td>\n",
       "      <td>June</td>\n",
       "      <td>5</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mukesh</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Allahabad</td>\n",
       "      <td>Diploma</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2021-09-05</td>\n",
       "      <td>2021</td>\n",
       "      <td>September</td>\n",
       "      <td>5</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name   Age    Address Qualification  Score       Date  start_year  \\\n",
       "0      Jai  44.0     Nagpur           MCA   31.0 2022-05-11        2022   \n",
       "1  Unknown  46.0    Unknown         B.com   59.5 2020-10-21        2020   \n",
       "2   Princi  48.0    Lucknow           Msc   88.0 2022-12-27        2022   \n",
       "3   Gaurav  58.0    Lucknow           Msc   77.0 2021-06-05        2021   \n",
       "4   Mukesh  26.0  Allahabad       Diploma   81.0 2021-09-05        2021   \n",
       "\n",
       "  start_month  start_date   week_day  \n",
       "0         May          11  Wednesday  \n",
       "1     October          21  Wednesday  \n",
       "2    December          27    Tuesday  \n",
       "3        June           5   Saturday  \n",
       "4   September           5     Sunday  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
